# -*- coding: utf-8 -*-
"""Stock analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ddhrf_9p9GQ48XVPfmVvvw3F96y98QCo
"""

!pip install -q langchain langgraph duckduckgo-search newspaper3k together pandas_ta scikit-learn matplotlib seaborn langchain_community lxml_html_clean

from google.colab import userdata
together_api_key=userdata.get('TOGETHER_API_KEY')

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
llm=ChatOpenAI(model="mistralai/Mixtral-8x7B-Instruct-v0.1",
                 temperature=0.0,
                 openai_api_key=together_api_key,
                 openai_api_base="https://api.together.xyz/v1",
                 max_tokens=1024
)

import os
from datetime import datetime, timedelta
import dateutil.parser

from langchain_core.messages import HumanMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END

import pandas as pd
import requests
from bs4 import BeautifulSoup as bs
import time
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from IPython.display import display

from duckduckgo_search import DDGS
from newspaper import Article
from sklearn.cluster import KMeans


@tool
def get_news_urls(query: str, max_results: int = 1) -> list[dict]:
    """
    Fetches news article URLs and titles based on a search query.
    Args:
        query (str): The search query for news.
        max_results (int): Maximum number of news articles to retrieve.
    Returns:
        list[dict]: A list of dictionaries, each containing 'title' and 'url'.
    """
    print(f"Searching for news with query: '{query}' (max_results: {max_results})")
    try:
        with DDGS() as ddgs:
            results = ddgs.news(query, region="wt-wt", safesearch="Moderate", max_results=max_results)
            return [{'title': r['title'], 'url': r['url']} for r in results]
    except Exception as e:
        print(f"Error fetching news URLs: {e}")
        return []

@tool
def extract_article_content(url: str) -> str:
    """
    Extracts the main text content from a given article URL.
    Args:
        url (str): The URL of the article to extract.
    Returns:
        str: The extracted article text, or an error message if extraction fails.
    """
    print(f"Extracting content from URL: {url}")
    try:
        article = Article(url)
        article.download()
        article.parse()
        return article.text
    except Exception as e:
        return f"Error extracting article from {url}: {e}"

@tool
def chartink_screener(url: str, scan_clause: dict) -> pd.DataFrame:
    """
    Scrapes stock data from Chartink.com based on a given URL and scan clause.
    Args:
        url (str): The Chartink screener URL.
        scan_clause (dict): A dictionary containing the 'scan_clause' for the POST request.
    Returns:
        pd.DataFrame: A DataFrame containing the scraped stock data,
                      including 'per_chg', 'rsi', 'close', and calculated
                      'entry', 'target', 'stop_loss' columns.
                      Returns an empty DataFrame on error.
    """
    print(f"Scraping Chartink for URL: {url} with clause: {scan_clause}")
    df = pd.DataFrame()
    try:
        with requests.Session() as s:
            r = s.get(url)
            soup = bs(r.text, "html.parser")
            csrf = soup.select_one("[name='csrf-token']")['content']
            s.headers['x-csrf-token'] = csrf
            s.headers['Content-Type'] = 'application/x-www-form-urlencoded'
            r = s.post('https://chartink.com/screener/process', data=scan_clause)
            df = pd.DataFrame().from_dict(r.json()['data'])

            df['per_chg'] = pd.to_numeric(df['per_chg'], errors='coerce')
            df['rsi'] = pd.to_numeric(df.get('rsi', 0), errors='coerce')
            df['close'] = pd.to_numeric(df.get('close', 0), errors='coerce')

            df = df.sort_values(by='per_chg', ascending=False)

            df['entry'] = df['close'] * 0.98
            df['target'] = df['close'] * 1.04
            df['stop_loss'] = df['close'] * 0.96

        return df
    except requests.exceptions.HTTPError as e:
        print(f"HTTP Error during Chartink scraping: {e}")
    except requests.exceptions.RequestException as e:
        print(f"Request Error during Chartink scraping: {e}")
    except Exception as e:
        print(f"An unexpected error occurred during Chartink scraping: {e}")
    return pd.DataFrame() # Return empty DataFrame on any error

@tool
def visualize_stock_data(df, strategy_name: str):
    """
    Generates a bubble chart visualization of stock data and displays top 5 stocks
    with entry/exit points.
    Args:
        df: The DataFrame containing stock data.
        strategy_name (str): The name of the strategy for the plot title.
    """
    print(f"Visualizing data for strategy: {strategy_name}")
    if df.empty:
        print("No data to visualize")
        return

    df['color'] = pd.cut(df['per_chg'],
                         bins=[-np.inf, 0, 5, 10, np.inf],
                         labels=['red', 'orange', 'lightgreen', 'darkgreen'])
    if len(df) > 3:
        try:
            kmeans = KMeans(n_clusters=min(3, len(df)), random_state=42, n_init='auto') # Added n_init for KMeans
            df['cluster'] = kmeans.fit_predict(df[['per_chg', 'rsi']])
        except Exception as e:
            print(f"KMeans clustering failed: {e}. Skipping clustering.")
            df['cluster'] = 0
    else:
        df['cluster'] = 0

    plt.figure(figsize=(12, 8))

    sns.scatterplot(data=df, x='rsi', y='per_chg',
                    hue='cluster', palette='viridis',
                    size='close', sizes=(20, 200),
                    alpha=0.7)

    plt.title(f'Stock Performance: {strategy_name}\nBubble Size = Market Cap')
    plt.xlabel('RSI (14)')
    plt.ylabel('Percentage Change')
    plt.axhline(0, color='grey', linestyle='--')
    plt.axvline(50, color='grey', linestyle='--')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

    if not df.empty:
        print("\nTop 5 Stocks with Entry/Exit Points (Risk:Reward 2:1):")
        top_df = df.head().copy()
        if 'entry' in top_df.columns and 'target' in top_df.columns and 'stop_loss' in top_df.columns:
            top_df['RR Ratio'] = (top_df['target'] - top_df['entry']) / (top_df['entry'] - top_df['stop_loss']).replace(0, np.nan)
            display(top_df[['nsecode', 'close', 'entry', 'target', 'stop_loss', 'RR Ratio']])
        else:
            print("Required columns for RR Ratio calculation are missing.")
            display(top_df[['nsecode', 'close', 'per_chg', 'rsi']])
    else:
        print("No stocks to display entry/exit points.")

tools = [get_news_urls, extract_article_content, chartink_screener, visualize_stock_data]

from typing import TypedDict, List, Dict, Any
import functools

class GraphState(TypedDict):
    """
    Represents the state of our graph.

    Attributes:
        query (str): The initial user query.
        news_articles (List[Dict[str, str]]): List of fetched news articles (title, url, content, sentiment).
        stock_data (Dict[str, pd.DataFrame]): Dictionary of stock data DataFrames by strategy name.
        llm_recommendation (str): The LLM's final stock recommendation.
        error_message (str): Any error message encountered during execution.
    """
    query: str
    news_articles: List[Dict[str, str]]
    stock_data: Dict[str, pd.DataFrame]
    llm_recommendation: str
    error_message: str

llm_with_tools = llm.bind_tools(tools)


# --- Agent Nodes ---

def news_fetcher_node(state: GraphState) -> GraphState:
    """
    Fetches news articles for the top stocks identified in the stock screener.
    """
    print("---NEWS FETCHER NODE---")
    stock_data = state.get("stock_data", {})
    main_df = stock_data.get("Smart Money", pd.DataFrame())

    articles_with_content = []

    if not main_df.empty:
        top_stocks = main_df.head(5)['nsecode'].tolist()
        for symbol in top_stocks:
            print(f"Fetching news for {symbol}...")
            news_results = get_news_urls.invoke({"query": symbol, "max_results": 2})
            for article_info in news_results:
                content = extract_article_content.invoke({"url": article_info['url']})
                articles_with_content.append({
                    "symbol": symbol,
                    "title": article_info['title'],
                    "url": article_info['url'],
                    "content": content
                })
    else:
        print("No stock data available to fetch news.")

    return {"news_articles": articles_with_content}

async def analyze_news_sentiment_node(state: GraphState) -> GraphState:
    """
    Analyzes sentiment of news articles per stock symbol.
    """
    print("---ANALYZE NEWS SENTIMENT NODE---")
    news_articles = state.get("news_articles", [])
    updated_articles = []

    for article in news_articles:
        content = article['content']
        symbol = article['symbol']

        if content.startswith("Error"):
            sentiment_analysis = "Sentiment: N/A\nRecommended Investment Action: N/A\nReason: Content extraction failed."
        else:
            text_chunk = content[:2000]
            prompt = f"""You are a financial news analyst. Read the article enclosed in triple backticks and analyse its sentiment categorizing it as: Positive, Neutral, Negative.
Then suggest possible investment action based on this with an explaination in no more than 30 words.

Structure your response in the following format with no other extra information:
Sentiment: Positive/Neutral/Negative
Recommended Investment Action: Buy/Hold/Sell
Reason: Explain why you would recommend this action in under 30 words.

```{text_chunk}```"""
            try:
                response = await llm.ainvoke([HumanMessage(content=prompt)])
                sentiment_analysis = response.content
            except Exception as e:
                sentiment_analysis = f"Sentiment: Error\nRecommended Investment Action: N/A\nReason: LLM call failed: {e}"

        updated_articles.append({**article, "sentiment_analysis": sentiment_analysis})
        print(f"[{symbol}] Sentiment for '{article['title']}':\n{sentiment_analysis}\n")

    return {"news_articles": updated_articles}

def stock_screener_node(state: GraphState) -> GraphState:
    """
    Scrapes stock data for predefined strategies.
    """
    print("---STOCK SCREENER NODE---")
    strategies = {
        'Smart Money': (
            'https://chartink.com/screener/strategy-1-499',
            {'scan_clause': '( {cash} ( latest close > latest ema( latest close , 200 ) and latest close > latest ema( latest close , 50 ) and latest ema( latest close , 50 ) > latest ema( latest close , 200 ) and latest rsi( 14 ) > 50 and latest macd signal( 26 , 12 , 9 ) > 0 and latest macd line( 26 , 12 , 9 ) > 0 and latest macd line( 26 , 12 , 9 ) > latest macd signal( 26 , 12 , 9 ) ) )'}
        ),
        'Momentum': (
            'https://chartink.com/screener/momentum',
            {'scan_clause': '( {cash} ( latest close > latest ema( latest close , 200 ) and latest rsi( 14 ) > 70 ) )'}
        )
    }
    all_stock_data = {}
    for name, (url, clause) in strategies.items():
        df = chartink_screener.invoke({"url": url, "scan_clause": clause})
        if not df.empty:
            all_stock_data[name] = df
        else:
            print(f"Failed to get data for strategy: {name}")

    return {"stock_data": all_stock_data}

def visualize_and_compare_node(state: GraphState) -> GraphState:
    """
    Visualizes individual strategy data and compares common stocks across strategies.
    """
    print("---VISUALIZE AND COMPARE NODE---")
    all_dfs = state.get("stock_data", {})
    common_stocks = None

    for name, df in all_dfs.items():
        print(f"\n--- Strategy: {name} Visualization ---")
        visualize_stock_data.invoke({"df": df, "strategy_name": name})
        if common_stocks is None:
            common_stocks = set(df['nsecode'])
        else:
            common_stocks = common_stocks.intersection(set(df['nsecode']))

    if common_stocks and len(common_stocks) > 0:
        print("\n--- Stocks common to all strategies ---")
        print(common_stocks)

        combined_data = []
        for stock in common_stocks:
            stock_data = {'Stock': stock}
            for name, df in all_dfs.items():
                stock_df = df[df['nsecode'] == stock]
                if not stock_df.empty:
                    stock_data[f'{name}_per_chg'] = stock_df.iloc[0]['per_chg']
                    stock_data[f'{name}_rsi'] = stock_df.iloc[0]['rsi']
            combined_data.append(stock_data)

        combined_df = pd.DataFrame(combined_data)
        print("\nCombined performance metrics for common stocks:")
        display(combined_df)
    else:
        print("\nNo common stocks across all strategies")

    return state
async def analyze_stocks_llm_node(state: GraphState) -> GraphState:
    """
    Analyzes stock + news sentiment to make final recommendations.
    """
    print("---ANALYZE STOCKS LLM NODE---")
    stock_data = state.get("stock_data", {})
    main_df = stock_data.get("Smart Money", pd.DataFrame())
    news_articles = state.get("news_articles", [])

    if main_df.empty:
        recommendation = "No stock data found to analyze for the main strategy."
    else:
        top_df = main_df.head(5)[['nsecode', 'close', 'per_chg', 'rsi', 'entry', 'target', 'stop_loss']]
        stock_info = top_df.to_string(index=False)

        sentiment_summary = ""
        for article in news_articles:
            symbol = article.get("symbol", "")
            sentiment = article.get("sentiment_analysis", "")
            sentiment_summary += f"\n[{symbol}] {sentiment}\n"

        prompt = f"""
You are a financial analyst reviewing technical and news sentiment data for top stocks.

--- Stock Screener Data ---
{stock_info}

--- News Sentiment Summary ---
{sentiment_summary}

Instructions:
1. Identify 2–3 good buy candidates based on both technicals and sentiment.
2. Justify each pick (RSI, momentum, risk/reward, sentiment, volume).
3. Highlight any risky or overhyped stocks to avoid.
4. If ₹10000 budget is available, suggest quantity allocation.

Give a clean and clear action plan.
"""
        try:
            response = await llm.ainvoke([HumanMessage(content=prompt)])
            recommendation = response.content
        except Exception as e:
            recommendation = f"Error during LLM stock analysis: {e}"

    print("\nLLM Agent Stock Recommendation:")
    print(recommendation)
    return {"llm_recommendation": recommendation}

from langgraph.graph import StateGraph, END

builder = StateGraph(GraphState)

builder.add_node("StockScreener", stock_screener_node)
builder.add_node("NewsFetcher", news_fetcher_node)
builder.add_node("NewsSentiment", analyze_news_sentiment_node)
builder.add_node("VisualCompare", visualize_and_compare_node)
builder.add_node("StockAnalyzer", analyze_stocks_llm_node)

builder.set_entry_point("StockScreener")
builder.add_edge("StockScreener", "NewsFetcher")
builder.add_edge("NewsFetcher", "NewsSentiment")
builder.add_edge("NewsSentiment", "VisualCompare")
builder.add_edge("VisualCompare", "StockAnalyzer")
builder.add_edge("StockAnalyzer", END)

graph = builder.compile()

initial_state = {
    "query": "Top stocks to trade",
    "stock_data": {},
    "news_articles": [],
    "llm_recommendation": "",
    "error_message": ""
}

final_state = await graph.ainvoke(initial_state)